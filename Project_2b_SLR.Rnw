\documentclass{article}

\usepackage{url}
\usepackage{graphicx,subfig}
\usepackage{float}
\usepackage{fullpage}

\title{Project 2 - SLR}
\author{Savanah Bird and Haley Land-Miller}
\date{Due: Monday, February 12, 2018, in class}


\begin{document}
\maketitle

<<global_options, include=FALSE, echo=FALSE>>=
knitr::opts_chunk$set(message=FALSE, warning=FALSE, fig.height=3, fig.width=5, fig.align = "center")
library(dplyr)
library(ggplot2)
library(broom)
library(readxl)
library(knitr)
options(digits=3)
@

\section*{Introduction}
Hi Savanah BIRD

Our dataset describes a sample of forest fires that occured in Montesinho Park in northern $Portugal^{1}$. For each fire there are a number of recorded variables that generally describe the environmnet at the time of the fire, such as region of the park, temperature, wind, and moisture. The variables are as follows:  

\begin{itemize}
\item
X - X-axis spatial coordinate within the Montesinho park map: 1 to 9. Continuous.
\item
Sector - X-axis spatial coordinate placed into broader sectors by us. 1-3 = West, 4-6 = Central, 7-9 = East. Categorical.
\item
month - Month of the year: 'jan' to 'dec'. Categorical.
\item
FFMC - FFMC index from the FWI system: 18.7 to 96.20. A numeric rating of the moisture content of litter and other cured fine fuels. Indicator of the relative ease of ignition and the flammability of fine fuel. Continuous.
\item
DMC - DMC index from the FWI system: 1.1 to 291.3. A numeric rating of the average moisture content of loosely compacted organic layers of moderate depth. Indicatior of fuel consumption in moderate duff layers and medium-size woody material. Continuous.
\item
DC - DC index from the FWI system: 7.9 to 860.6. A numeric rating of the average moisture content of deep, compact organic layers. Indicator of seasonal drought effects on forest fuels and the amount of smoldering in deep duff layers and large logs. Continuous.
\item
DCcat - DC variables placed into categories by us. <150 = Low, 150-550 = Mid, >550 = High. Categorical.
\item
ISI - ISI index from the FWI system: 0.0 to 56.10. A numeric rating of the expected rate of fire spread. It combines the effects of wind and the FFMC on rate of spread without the influence of variable quantities of fuel. Continuous.
\item
temp - temperature in Celsius degrees: 2.2 to 33.30. Continuous. 
\item
RH - relative humidity in %: 15.0 to 100. Continuous.
\item
wind - wind speed in km/h: 0.40 to 9.40. Continuous.
\item
rain - outside rain in mm/m2 : 0.0 to 6.4. Continuous.
\item
Raincat - No if rain = 0, Yes if rain > 0. Categorical. 
\end{itemize}

Our response variable of interest is the total area burned by the fire (variable name "area"), which ranges from 0.00 to 1090.84 ha. This is an important variable to predict as wildfires become increasingly common in human-occupied spaces. The goal of our project is to understand what factors contribute to forest fire size. In this part of the project, we will create a simple linear regression to understand the relationship between temperature and area burned by the forest fire. We hypothesize that area burned and temperature are linearly related, and that they have a positive relationship.   


$H_0$: $\beta_1 = 0$

$H_a$: $\beta_1 > 0$

\section*{Simple Linear Regression}

<<message=FALSE, warning=FALSE, echo=FALSE>>=
Fires <- readxl::read_excel(path = "~/Desktop/School Work/Semester 8!/Slodels HW/SlodelsProject/Forestfires_forR.xlsx",sheet=1)

plot(Fires$temp, Fires$area,
     ylab="Area burned (ha)", xlab="Temperature (celcius)", 
     main="Area burned vs. temperature") 

temp_lm <- lm(Fires$area ~ Fires$temp, data=Fires)
temp_aug <- augment(temp_lm)
area.resid <- temp_aug$.std.resid
exp.burn <- fitted(temp_lm)
@

<<eval=FALSE, echo=FALSE>>=
plot(exp.burn, area.resid,
     ylab="Standardized residuals", xlab="Expected area burned", 
     main="Standardized residual plot")
@

From this plot, it is clear that the data are not linear and that there is not constant variability. We will take the log of 1 + the response variable. A log transform on its own would not work, as many of our response variable values are zero. 

<<message=FALSE, warning=FALSE, echo=FALSE>>=
logplusone_area <- log(Fires$area+1)
plot(Fires$temp, logplusone_area,
     ylab="log(Area burned (ha) + 1)", xlab="Temperature (celcius)", 
     main="Log(Area burned+1) vs. temperature") 

logplusone_temp_lm <- lm(logplusone_area ~ Fires$temp, data=Fires)
logplusone_temp_aug <- augment(logplusone_temp_lm)
logplusone_area.resid <- logplusone_temp_aug$.std.resid
logplusone_exp.burn <- fitted(logplusone_temp_lm)
plot(logplusone_exp.burn, logplusone_area.resid,
     ylab="Standardized residuals", xlab="Expected Y value", 
     main="Standardized residuals plot")
@
This transformation of our data is somewhat successful. Our y-values are more spread out, but we still have an extremely dense set of points at $Y=1$, because many of the fires had a burned area of $0$. The residual plot shows this same trend, with many points at and just below zero. Clearly, our residuals are not normally distributed, and it would not be appropriate to make any inferences from this model. 

To deal with this issue, we decided to try excluding all fires that had a burned area of zero. This is reasonable, because when estimating fire size, we really want to know how many hectares fires burned in relation to various environmental factors. We're not asking whether or not a fire burned \textit{any} area, in which case we might want to consider a binary response variable (burned $>0$ hectares vs. burned $0$ hectares). We really want to know is, if a fire is burning some area of land, how big is that area? Therefore, it seems reasonable to exclude the observations with area $=0$. 

When doing this, we find that the plot of just area burned vs. temperature looks almost the same as when we included the area $=0$ observations. This is because the scale on our $y$-axis goes up to $>1000$, and many of our $y$-values are still very close to zero. However, when we transform the data by taking the log of the $y$-values, we get a much more appropriate distribution:

<<eval=TRUE, echo=FALSE>>=
Fires <- readxl::read_excel(path = "~/Desktop/School Work/Semester 8!/Slodels HW/SlodelsProject/Forestfires_forR.xlsx",sheet=2)
lognozero_area <- log(Fires$area)
plot(Fires$temp, lognozero_area,
     ylab="log(Area burned (ha))", xlab="Temperature (celcius)", 
     main="Log(Area burned) vs. temperature, area>0") 

lognozero_temp_lm <- lm(lognozero_area ~ temp, data=Fires)
lognozero_temp_aug <- augment(lognozero_temp_lm)
lognozero_area.resid <- lognozero_temp_aug$.std.resid
lognozero_exp.burn <- fitted(lognozero_temp_lm)
plot(lognozero_exp.burn, lognozero_area.resid,
     ylab="Standardized residuals", xlab="Expected Y value", 
     main="Standardized residuals plot")
@

There still doesn't appear to be a particularly clear linear relationship, but the residual plot is much more evenly distributed and suggests that we could attempt to make a model and infer some things from it. 
<<eval=TRUE, echo=FALSE>>=
kable(tidy(lognozero_temp_lm))
@

This gives us the model $log(\hat{y_i})=-.009x_i + 2.009$. The p-value of our test is $0.286$, because our test was one-tailed, not two. However, our hypothesis was that $\beta_1 > 0$, and in fact, the $b_1$ of our model is negative. That said, because we transformed our data, this model actually tells us that (assuming the technical conditions hold) a one unit increase in x is consistant with an $e^{-.009} = 0.991$ multiplicative change in median(Y). Our test tells us that if $\beta_1$ were equal to or less than zero, we would have 28.6\% chance of observing our data. Our residual plot looks fairly evenly spread out, so the linear model may be appropriate. However, our $R^2$ value is 0.00119, suggesting that our model only explains a very minimal amount of the variation in $y$. 

<<eval=TRUE, echo=FALSE, include=FALSE>>=
summary(lognozero_temp_lm)
@
<<eval=TRUE, echo=FALSE, include=FALSE>>=
broom::augment(lognozero_temp_lm)%>% head()

temp_3 <- (data.frame(temp=c(3)))
crit_val <- qt(.975, glance(lognozero_temp_lm)$df.resid)
temp_pred <- augment(lognozero_temp_lm, newdata=temp_3, type.predict = "response")
temp_pred <- temp_pred %>%
mutate(lower_CI = .fitted - crit_val * .se.fit,
upper_CI = .fitted + crit_val * .se.fit)
# the SE of the predictions also include the overall variability of the model
.se.pred <- sqrt(glance(lognozero_temp_lm)$sigma^2 + temp_pred$.se.fit)
temp_pred <- temp_pred %>%
mutate(lower_PI = .fitted - crit_val * .se.pred,
       upper_PI = .fitted + crit_val * .se.pred,
      lower_CI = .fitted - crit_val * .se.fit,
      upper_CI = .fitted + crit_val * .se.fit)
temp_pred
@
<<eval=TRUE, echo=FALSE, include=FALSE>>=
broom::augment(lognozero_temp_lm)%>% head()

temp_mean <- (data.frame(temp=c(mean(Fires$temp))))
crit_val <- qt(.975, glance(lognozero_temp_lm)$df.resid)
temp_pred <- augment(lognozero_temp_lm, newdata=temp_mean, type.predict = "response")
temp_pred <- temp_pred %>%
mutate(lower_CI = .fitted - crit_val * .se.fit,
upper_CI = .fitted + crit_val * .se.fit)
# the SE of the predictions also include the overall variability of the model
.se.pred <- sqrt(glance(lognozero_temp_lm)$sigma^2 + temp_pred$.se.fit)
temp_pred <- temp_pred %>%
mutate(lower_PI = .fitted - crit_val * .se.pred,
       upper_PI = .fitted + crit_val * .se.pred,
      lower_CI = .fitted - crit_val * .se.fit,
      upper_CI = .fitted + crit_val * .se.fit)
temp_pred
@
The 95\% confidence interval for our mean temperature is (1.66,2.03). This means that at our mean temperature (which is 19.3 degrees celsius), 95\% of our fires had areas of between $e^{1.66} - e^{2.03}$ hectares. We might also be interested in the size of fires at the mean temperature in Germany in January, which is 3 degrees celsius. The 95\% confidence interval for fires that happened when it was 3 degrees is (1.47, 2.5), meaning that 95\% of fires had areas between $e^{1.47}-e^{2.5}$ hectares.
\section*{Additional analysis}


<<eval=TRUE, echo=FALSE, out.width ='3in'>>=
knitr::opts_chunk$set(message=FALSE, warning=FALSE, fig.height=2, fig.width=5, out.height="2in", out.width="4in", fig.align = "center")
#No adjustment
temp_gl <- broom::glance(lognozero_temp_lm)
temp_sig <- dplyr::pull(temp_gl, sigma)
temp_pred <- broom::augment(lognozero_temp_lm) %>%
mutate(.se.pred = sqrt(temp_sig^2 + .se.fit^2)) %>%
mutate(lower_PI = .fitted - crit_val*.se.pred,
upper_PI = .fitted + crit_val*.se.pred,
lower_CI = .fitted - crit_val * .se.fit,
upper_CI = .fitted + crit_val * .se.fit)
#temp_pred %>% head()
ggplot(temp_pred, aes(x = Fires$temp, y = lognozero_area)) + geom_point() +
stat_smooth(method = "lm", se = FALSE) +
geom_ribbon(aes(ymin = lower_PI, ymax = upper_PI), alpha = .2) +
geom_ribbon(data = temp_pred, aes(ymin = lower_CI, ymax = upper_CI), alpha = .2, fill = "red") +
ggtitle("Simultaneous inference, no adjustment") +
  xlab("Temperature (celcius)") + ylab("log(Area burned (ha))")

#Working-Hotelling
num_int <- 3
crit_WH <- sqrt(2*qf(.95, num_int, glance(lognozero_temp_lm)$df.resid))
temp_gl <- broom::glance(lognozero_temp_lm)
temp_sig <- dplyr::pull(temp_gl, sigma)
temp_pred <- broom::augment(lognozero_temp_lm) %>%
mutate(.se.pred = sqrt(temp_sig^2 + .se.fit^2)) %>%
mutate(lower_PI = .fitted - crit_WH*.se.pred,
upper_PI = .fitted + crit_WH*.se.pred,
lower_CI = .fitted - crit_WH * .se.fit,
upper_CI = .fitted + crit_WH * .se.fit)
#temp_pred %>% head()
ggplot(temp_pred, aes(x = Fires$temp, y = lognozero_area)) + geom_point() +
stat_smooth(method = "lm", se = FALSE) +
geom_ribbon(aes(ymin = lower_PI, ymax = upper_PI), alpha = .2) +
geom_ribbon(data = temp_pred, aes(ymin = lower_CI, ymax = upper_CI), alpha = .2, fill = "red")+
ggtitle("Simultaneous inference, Working-Hotelling adjustment") +
  xlab("Temperature (celcius)") + ylab("log(Area burned (ha))")

#Bonferroni
crit_Bonf <- qt((1-.975)/num_int, glance(lognozero_temp_lm)$df.resid)
temp_gl <- broom::glance(lognozero_temp_lm)
temp_sig <- dplyr::pull(temp_gl, sigma)
temp_pred <- broom::augment(lognozero_temp_lm) %>%
mutate(.se.pred = sqrt(temp_sig^2 + .se.fit^2)) %>%
mutate(lower_PI = .fitted - crit_Bonf*.se.pred,
upper_PI = .fitted + crit_Bonf * .se.pred,
lower_CI = .fitted - crit_Bonf * .se.fit,
upper_CI = .fitted + crit_Bonf * .se.fit)
#temp_pred %>% head()
ggplot(temp_pred, aes(x = Fires$temp, y = lognozero_area)) + geom_point() +
stat_smooth(method = "lm", se = FALSE) +
geom_ribbon(aes(ymin = lower_PI, ymax = upper_PI), alpha = .2) +
geom_ribbon(data = temp_pred, aes(ymin = lower_CI, ymax = upper_CI), alpha = .2, fill = "red")+
ggtitle("Simultaneous inference, Bonferroni adjustment") +
  xlab("Temperature (celcius)") + ylab("log(Area burned (ha))")
@

In both mean confidence intervals and prediction intervals, the Bonferroni intervals are the largest, followed by the Working-Hotelling intervals and finally the no adjustment intervals. It's important to adjust for multiple comparisons so that we can more accurately contain our data in our intervals for all values of x. Bonferroni is not the most useful for communicating results, as it is the most conservative. 
\section*{Conclusions}
Our original data set was difficult to fit a model to, as a large proportion of the response variable values were zero. Upon taking out those observations, we were able to fit a linear model with a log-transformed response variable. Even so, the model explained only a small about of variation in the total area burned by the fire. Ultimately, we could not reject the null hypothesis. For future steps, we would want to incorporate more explanatory variables into our model to see if the model would improve.

\section*{References}

$^{1}$ P. Cortez and A. Morais. A Data Mining Approach to Predict Forest Fires using Meteorological Data. In J. Neves, M. F. Santos and J. Machado Eds., New Trends in Artificial Intelligence, Proceedings of the 13th EPIA 2007 - Portuguese Conference on Artificial Intelligence, December, Guimar√£es, Portugal, pp. 512-523, 2007. APPIA, ISBN-13 978-989-95618-0-9.

https://archive.ics.uci.edu/ml/datasets/forest+fires


\noindent{\textbf{Github repository:} https://github.com/hlandmiller/SlodelsProject}
\end{document}